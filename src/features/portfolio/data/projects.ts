import type { Project } from "../types/projects";

export const PROJECTS: Project[] = [
  {
    id: "react-wheel-picker",
    title: "Kinetiq â€” Distributed Event Booking System",
    period: {
      start: "09.2025",
      end :  "10.2025"
    },
    link: "https://github.com/dkb73/Kinetiq",
    skills: [
      "React.js",
      "Node.js",
      "Kafka",
      "PostgreSQL",
      "MongoDB",
      "Redis",
      "Docker",
      "NGINX",
      "Microservices",
      "Distributed Systems",
    ],
    description: `Asynchronous, distributed event booking system built using Kafka + polyglot persistence with PostgreSQL (write) and MongoDB (read).
- âš¡ High-throughput booking via Kafka queue + worker pool
- ğŸ”„ Background data-sync service ensuring read/write store consistency
- ğŸ—„ Polyglot persistence: PostgreSQL for transactional integrity, MongoDB for low-latency reads
- ğŸ” Distributed locking via Redis to prevent race-conditions during ticket booking
- ğŸŒ NGINX reverse proxy as unified gateway for frontend + APIs
- ğŸ³ Fully containerized â€” one-command startup with Docker Compose
`,
    logo: "https://assets.chanhdai.com/images/project-logos/react-wheel-picker.svg",
    isExpanded: true,
  },
  {
    id: "chanhdaidotcom",
    title: "BulkProcessor â€” CSV Processing System",
    period: {
      start: "01.2025",
    },
    link: "https://github.com/dkb73/BulkProcessor",
    skills: [
    "React.js",
    "Node.js",
    "MongoDB",
    "BullMQ",
    "Redis",
    "Socket.io",
    "Streams",
    "Background Workers",
    "Batch Processing",
    ],
    description: `Full-stack CSV ingestion pipeline with scalable background processing and real-time UI feedback.
- âš™ï¸ Non-blocking CSV parsing using Node streams + BullMQ worker queues
- ğŸ” Event-driven architecture with Redis Pub/Sub for live progress updates
- ğŸ“¤ Socket.io integration for instant client feedback during processing
- ğŸ—„ Bulk inserts into MongoDB for high-throughput ingestion
- ğŸ”— Decoupled API + worker design â†’ eliminates request timeouts and enables independent scaling

Handles large uploads efficiently with real-time job tracking, error logging, and async ingestion into persistent storage`,
    logo: "https://assets.chanhdai.com/images/project-logos/chanhdaidotcom.svg",
  },
  // {
  //   id: "quaricdotcom",
  //   title: "quaric.com",
  //   period: {
  //     start: "03.2024",
  //   },
  //   link: "https://quaric.com",
  //   skills: [
  //     "Company Project",
  //     "Next.js 15",
  //     "Tailwind CSS v3",
  //     "shadcn/ui",
  //     "Strapi 5",
  //     "VNPAY-QR",
  //     "Docker",
  //     "Docker Compose",
  //     "NGINX",
  //   ],
  //   logo: "https://assets.chanhdai.com/images/project-logos/quaricdotcom.svg",
  // }
];
